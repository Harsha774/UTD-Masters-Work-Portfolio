{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network_Project_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "77tvlPOhzBkq"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# LOGISTICS\n",
        "#\n",
        "#    Kapil Gautam\n",
        "#    KXG180032\n",
        "#\n",
        "# DESCRIPTION\n",
        "#\n",
        "#    Image classification in PyTorch for ImageNet reduced to 100 classes and\n",
        "#    down sampled such that the short side is 64 pixels and the long side is\n",
        "#    >= 64 pixels\n",
        "#\n",
        "#    This script achieved a best accuracy of 71.24% on epoch 26 with a learning\n",
        "#    rate at that point of 0.001 and time required for each epoch of ~ 152.19 s\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "#    2. File - New Python 3 notebook\n",
        "#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)\n",
        "#    4. Runtime - Run all\n",
        "#\n",
        "# NOTES\n",
        "#\n",
        "#    0. For a mapping of category names to directory names see:\n",
        "#       https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n",
        "#\n",
        "#    1. The original 2012 ImageNet images are down sampled such that their short\n",
        "#       side is 64 pixels (the other side is >= 64 pixels) and only 100 of the\n",
        "#       original 1000 classes are kept.\n",
        "#\n",
        "#    2. Build and train a RegNetX image classifier modified as follows:\n",
        "#\n",
        "#       - Set stride = 1 (instead of stride = 2) in the stem\n",
        "#       - Replace the first stride = 2 down sampling building block in the\n",
        "#         original network by a stride = 1 normal building block\n",
        "#       - The fully connected layer in the decoder outputs 100 classes instead\n",
        "#         of 1000 classes\n",
        "#\n",
        "#       The original RegNetX takes in 3x224x224 input images and generates Nx7x7\n",
        "#       feature maps before the decoder, this modified RegNetX will take in\n",
        "#       3x56x56 input images and generate Nx7x7 feature maps before the decoder.\n",
        "#       For reference, an implementation of this network took ~ 112 s per epoch\n",
        "#       for training, validation and checkpoint saving on Sep 27, 2020 using a\n",
        "#       free GPU runtime in Google Colab.\n",
        "#\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ-hbWEgzDse"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# IMPORT\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn       as     nn\n",
        "import torch.optim    as     optim\n",
        "from   torch.autograd import Function\n",
        "\n",
        "# torch utils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# additional libraries\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import time\n",
        "import math\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfpcBgOezKea"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# PARAMETERS\n",
        "#\n",
        "################################################################################\n",
        "# data\n",
        "DATA_DIR_1        = 'data'\n",
        "DATA_DIR_2        = 'data/imagenet64'\n",
        "DATA_DIR_TRAIN    = 'data/imagenet64/train'\n",
        "DATA_DIR_TEST     = 'data/imagenet64/val'\n",
        "DATA_FILE_TRAIN_1 = 'Train1.zip'\n",
        "DATA_FILE_TRAIN_2 = 'Train2.zip'\n",
        "DATA_FILE_TRAIN_3 = 'Train3.zip'\n",
        "DATA_FILE_TRAIN_4 = 'Train4.zip'\n",
        "DATA_FILE_TRAIN_5 = 'Train5.zip'\n",
        "DATA_FILE_TEST_1  = 'Val1.zip'\n",
        "DATA_URL_TRAIN_1  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train1.zip'\n",
        "DATA_URL_TRAIN_2  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train2.zip'\n",
        "DATA_URL_TRAIN_3  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train3.zip'\n",
        "DATA_URL_TRAIN_4  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train4.zip'\n",
        "DATA_URL_TRAIN_5  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train5.zip'\n",
        "DATA_URL_TEST_1   = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Val1.zip'\n",
        "DATA_BATCH_SIZE   = 256\n",
        "DATA_NUM_WORKERS  = 4\n",
        "DATA_NUM_CHANNELS = 3\n",
        "DATA_NUM_CLASSES  = 100\n",
        "DATA_RESIZE       = 64\n",
        "DATA_CROP         = 56\n",
        "DATA_MEAN         = (0.485, 0.456, 0.406)\n",
        "DATA_STD_DEV      = (0.229, 0.224, 0.225)\n",
        "SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7DaLpRYz8Z7"
      },
      "source": [
        "# model\n",
        "# add model parameters here\n",
        "MODEL_LEVEL_0_BLOCKS            = 1\n",
        "MODEL_LEVEL_1_BLOCKS            = 1\n",
        "MODEL_LEVEL_2_BLOCKS            = 4\n",
        "MODEL_LEVEL_3_BLOCKS            = 7\n",
        "MODEL_TAIL_END_CHANNELS         = 24\n",
        "MODEL_LEVEL_0_IDENTITY_CHANNELS = 24\n",
        "MODEL_LEVEL_1_IDENTITY_CHANNELS = 56\n",
        "MODEL_LEVEL_2_IDENTITY_CHANNELS = 152\n",
        "MODEL_LEVEL_3_IDENTITY_CHANNELS = 368\n",
        "\n",
        "# training\n",
        "# add training parameters here\n",
        "# training (linear warm up with cosine decay learning rate)\n",
        "TRAINING_LR_MAX          = 0.01\n",
        "TRAINING_LR_INIT_SCALE   = 0.1\n",
        "TRAINING_LR_INIT_EPOCHS = 3\n",
        "TRAINING_LR_FINAL_SCALE = 0.1\n",
        "TRAINING_LR_FINAL_EPOCHS = 23\n",
        "TRAINING_NUM_EPOCHS      = TRAINING_LR_INIT_EPOCHS + TRAINING_LR_FINAL_EPOCHS\n",
        "TRAINING_LR_INIT         = TRAINING_LR_MAX*TRAINING_LR_INIT_SCALE\n",
        "TRAINING_LR_FINAL        = TRAINING_LR_MAX*TRAINING_LR_FINAL_SCALE\n",
        "\n",
        "# file\n",
        "# add file parameters here\n",
        "FILE_NAME = 'RegNetX-200MF.pt'\n",
        "FILE_SAVE = 0\n",
        "FILE_LOAD = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDIcLlpvzOh6"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# DATA\n",
        "#\n",
        "################################################################################\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# create a local directory structure for data storage\n",
        "if (os.path.exists(DATA_DIR_1) == False):\n",
        "    os.mkdir(DATA_DIR_1)\n",
        "if (os.path.exists(DATA_DIR_2) == False):\n",
        "    os.mkdir(DATA_DIR_2)\n",
        "if (os.path.exists(DATA_DIR_TRAIN) == False):\n",
        "    os.mkdir(DATA_DIR_TRAIN)\n",
        "if (os.path.exists(DATA_DIR_TEST) == False):\n",
        "    os.mkdir(DATA_DIR_TEST)\n",
        "\n",
        "# download data\n",
        "if (os.path.exists(DATA_FILE_TRAIN_1) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_1, DATA_FILE_TRAIN_1)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_2) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_2, DATA_FILE_TRAIN_2)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_3) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_3, DATA_FILE_TRAIN_3)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_4) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_4, DATA_FILE_TRAIN_4)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_5) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_5, DATA_FILE_TRAIN_5)\n",
        "if (os.path.exists(DATA_FILE_TEST_1) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_1, DATA_FILE_TEST_1)\n",
        "\n",
        "# extract data\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_2, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_3, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_4, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_5, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TEST_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TEST)\n",
        "\n",
        "# transforms\n",
        "transform_train = transforms.Compose([transforms.RandomResizedCrop(DATA_CROP),\n",
        "                  transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])\n",
        "transform_test  = transforms.Compose([transforms.Resize(DATA_RESIZE), transforms.CenterCrop(DATA_CROP),\n",
        "                                      transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mgXGHVQW06j"
      },
      "source": [
        "# data sets\n",
        "dataset_train = torchvision.datasets.ImageFolder(DATA_DIR_TRAIN, transform=transform_train)\n",
        "dataset_test  = torchvision.datasets.ImageFolder(DATA_DIR_TEST,  transform=transform_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPy5VQwnW2QR"
      },
      "source": [
        "# data loader\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=DATA_BATCH_SIZE, shuffle=True,\n",
        "                                               num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size=DATA_BATCH_SIZE, shuffle=False,\n",
        "                                               num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f12AcjjBzSMe"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# NETWORK BUILDING BLOCK\n",
        "#\n",
        "################################################################################\n",
        "# X block\n",
        "class XBlock(nn.Module):\n",
        "    # initialization\n",
        "    def __init__(self, Ni, No, Fr=3, Fc=3, Sr=1, Sc=1, G=8):\n",
        "\n",
        "        # parent initialization\n",
        "        super(XBlock, self).__init__()\n",
        "\n",
        "        # operations needed to create a parameterized XBlock\n",
        "        C_res = Ni\n",
        "        # identity\n",
        "        if ((Ni != No) or (Sr > 1)):\n",
        "            self.conv0_present = True\n",
        "            self.conv0         = nn.Conv2d(Ni, No, (1, 1), stride=(Sr, Sc), padding=(0, 0), dilation=(1, 1),\n",
        "                                           groups=G, bias=False, padding_mode='zeros')\n",
        "        else:\n",
        "            self.conv0_present = False\n",
        "\n",
        "        # residual\n",
        "        self.bn1   = nn.BatchNorm2d(Ni, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(Ni, C_res, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1),\n",
        "                               bias=False, padding_mode='zeros')\n",
        "        \n",
        "        self.bn2   = nn.BatchNorm2d(C_res, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(C_res, C_res, (Fr, Fc), stride=(Sr, Sc), padding=(1, 1), dilation=(1, 1),\n",
        "                               groups=G, bias=False, padding_mode='zeros')\n",
        "        \n",
        "        self.bn3   = nn.BatchNorm2d(C_res, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.conv3 = nn.Conv2d(C_res, No, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1),\n",
        "                               bias=False, padding_mode='zeros')\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "        # tie together the operations to create a parameterized XBlock\n",
        "        # residual\n",
        "        res = self.bn1(x)\n",
        "        res = self.relu1(res)\n",
        "        res = self.conv1(res)\n",
        "        res = self.bn2(res)\n",
        "        res = self.relu2(res)\n",
        "        res = self.conv2(res)\n",
        "        res = self.bn3(res)\n",
        "        res = self.relu3(res)\n",
        "        res = self.conv3(res)\n",
        "\n",
        "        # identity\n",
        "        if (self.conv0_present == True):\n",
        "          x = self.conv0(x)\n",
        "\n",
        "        # summation\n",
        "        x = x + res\n",
        "\n",
        "        # return\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJtorskXzYSp"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# NETWORK\n",
        "#\n",
        "################################################################################\n",
        "# define\n",
        "class Model(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, data_num_channels, data_num_classes, model_level_0_blocks, model_level_1_blocks,\n",
        "                 model_level_2_blocks, model_level_3_blocks, model_tail_end_channels, model_level_0_identity_channels, \n",
        "                 model_level_1_identity_channels, model_level_2_identity_channels, model_level_3_identity_channels):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # operations needed to create a modified RegNetX-200MF network\n",
        "        # use the parameterized XBlock defined to simplify this section\n",
        "\n",
        "        # encoder tail\n",
        "        self.enc_tail = nn.ModuleList()\n",
        "        self.enc_tail.append(nn.Conv2d(data_num_channels, model_tail_end_channels, (3, 3), stride=(1, 1),\n",
        "                                       padding=(1, 1), dilation=(1, 1), bias=False, padding_mode='zeros'))\n",
        "\n",
        "        # encoder level 0 - depth 1\n",
        "        self.enc_0 = nn.ModuleList()\n",
        "        self.enc_0.append(XBlock(model_tail_end_channels, model_level_0_identity_channels))\n",
        "        \n",
        "        # encoder level 1 - depth 1\n",
        "        self.enc_1 = nn.ModuleList()\n",
        "        self.enc_1.append(XBlock(model_level_0_identity_channels, model_level_1_identity_channels, Sr=2, Sc=2))\n",
        "        \n",
        "        # encoder level 2 - depth 4\n",
        "        self.enc_2 = nn.ModuleList()\n",
        "        self.enc_2.append(XBlock(model_level_1_identity_channels, model_level_2_identity_channels, Sr=2, Sc=2))\n",
        "        for n in range(model_level_2_blocks - 1):\n",
        "            self.enc_2.append(XBlock(model_level_2_identity_channels, model_level_2_identity_channels))\n",
        "\n",
        "        # encoder level 3 - depth 7\n",
        "        self.enc_3 = nn.ModuleList()\n",
        "        self.enc_3.append(XBlock(model_level_2_identity_channels, model_level_3_identity_channels, Sr=2, Sc=2))\n",
        "        for n in range(model_level_3_blocks - 1):\n",
        "            self.enc_3.append(XBlock(model_level_3_identity_channels, model_level_3_identity_channels))\n",
        "\n",
        "        # encoder level 3 complete the (conv) - bn - relu pattern\n",
        "        self.enc_3.append(nn.BatchNorm2d(model_level_3_identity_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
        "        self.enc_3.append(nn.ReLU())\n",
        "\n",
        "        # decoder\n",
        "        self.dec = nn.ModuleList()\n",
        "        self.dec.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
        "        self.dec.append(nn.Flatten())\n",
        "        self.dec.append(nn.Linear(model_level_3_identity_channels, data_num_classes, bias=True))\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "        # tie together the operations to create a modified RegNetX-200MF\n",
        "        # encoder tail\n",
        "        for layer in self.enc_tail:\n",
        "            x = layer(x)\n",
        "\n",
        "        # encoder level 0\n",
        "        for layer in self.enc_0:\n",
        "            x = layer(x)\n",
        "\n",
        "        # encoder level 1\n",
        "        for layer in self.enc_1:\n",
        "            x = layer(x)\n",
        "\n",
        "        # encoder level 2\n",
        "        for layer in self.enc_2:\n",
        "            x = layer(x)\n",
        "\n",
        "        # encoder level 3\n",
        "        for layer in self.enc_3:\n",
        "            x = layer(x)\n",
        "\n",
        "        # decoder\n",
        "        for layer in self.dec:\n",
        "            x = layer(x)\n",
        "\n",
        "        # return\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnPsAS8JzbG6"
      },
      "source": [
        "# create\n",
        "model = Model(DATA_NUM_CHANNELS, DATA_NUM_CLASSES, MODEL_LEVEL_0_BLOCKS, MODEL_LEVEL_1_BLOCKS, MODEL_LEVEL_2_BLOCKS,\n",
        "              MODEL_LEVEL_3_BLOCKS, MODEL_TAIL_END_CHANNELS, MODEL_LEVEL_0_IDENTITY_CHANNELS, \n",
        "              MODEL_LEVEL_1_IDENTITY_CHANNELS, MODEL_LEVEL_2_IDENTITY_CHANNELS,\n",
        "              MODEL_LEVEL_3_IDENTITY_CHANNELS)\n",
        "\n",
        "# visualization\n",
        "# print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2VJ9ahVjX-O"
      },
      "source": [
        "# specify the device as the GPU if present with fallback to the CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOO5kxepzfQ8"
      },
      "source": [
        "# enable data parallelization for multi GPU systems\n",
        "if (torch.cuda.device_count() > 1):\n",
        "    model = nn.DataParallel(model)\n",
        "print('Using {0:d} GPU(s)'.format(torch.cuda.device_count()), flush=True)\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# ERROR AND OPTIMIZER\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# define the error criteria and optimizer\n",
        "start_epoch = 0\n",
        "\n",
        "# learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "\n",
        "    # linear warmup followed by cosine decay\n",
        "    if epoch < TRAINING_LR_INIT_EPOCHS:\n",
        "        lr = (TRAINING_LR_MAX - TRAINING_LR_INIT)*(float(epoch)/TRAINING_LR_INIT_EPOCHS) + TRAINING_LR_INIT\n",
        "    else:\n",
        "        lr = (TRAINING_LR_MAX - TRAINING_LR_FINAL)*max(0.0, \n",
        "              math.cos(((float(epoch) - TRAINING_LR_INIT_EPOCHS)/(TRAINING_LR_FINAL_EPOCHS - 1.0))*(math.pi/2.0))) + TRAINING_LR_FINAL\n",
        "\n",
        "    return lr\n",
        "\n",
        "# error (softmax cross entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=TRAINING_LR_INIT, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "# transfer the network to the device\n",
        "model.to(device)\n",
        "\n",
        "# model loading\n",
        "if FILE_LOAD == 1:\n",
        "    checkpoint = torch.load(FILE_NAME)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfh5VYiDnA-5"
      },
      "source": [
        "import time\n",
        "train_start_time = time.time()\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3iLQqCyjkZL"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# TRAINING\n",
        "#\n",
        "################################################################################\n",
        "# perform network training, validation and checkpoint saving\n",
        "# cycle through the epochs\n",
        "for epoch in range(start_epoch, TRAINING_NUM_EPOCHS):\n",
        "\n",
        "    epoch_start_time = time.time()\n",
        "    # initialize train set statistics\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    num_batches   = 0\n",
        "\n",
        "    # set the learning rate for the epoch\n",
        "    for g in optimizer.param_groups:\n",
        "        g['lr'] = lr_schedule(epoch)\n",
        "\n",
        "    # cycle through the train set\n",
        "    for data in dataloader_train:\n",
        "\n",
        "        # extract a batch of data and move it to the appropriate device\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass, loss, backward pass and weight update\n",
        "        outputs = model(inputs)\n",
        "        loss    = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update statistics\n",
        "        training_loss = training_loss + loss.item()\n",
        "        num_batches   = num_batches + 1\n",
        "\n",
        "    # initialize test set statistics\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total   = 0\n",
        "\n",
        "    # no weight update / no gradient needed\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # cycle through the test set\n",
        "        for data in dataloader_test:\n",
        "\n",
        "            # extract a batch of data and move it to the appropriate device\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward pass and prediction\n",
        "            outputs      = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # update test set statistics\n",
        "            test_total   = test_total + labels.size(0)\n",
        "            test_correct = test_correct + (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    # epoch statistics\n",
        "    print('Epoch {0:2d} time {1:4.3f} lr = {2:8.6f} avg loss = {3:8.6f} accuracy = {4:5.2f}'.format(epoch,\n",
        "          epoch_end_time - epoch_start_time, lr_schedule(epoch), (training_loss/num_batches)/DATA_BATCH_SIZE,\n",
        "          (100.0*test_correct/test_total)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vluqs5SinC79"
      },
      "source": [
        "train_end_time = time.time()\n",
        "print(\"Total time taken = \", train_end_time - train_start_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmJmnLKwkFqb"
      },
      "source": [
        "# model saving\n",
        "# to use this for checkpointing put this code block inside the training loop at the end (e.g., just indent it 4 spaces)\n",
        "# and set 'epoch' to the current epoch instead of TRAINING_NUM_EPOCHS - 1; then if there's a crash it will be possible\n",
        "# to load this checkpoint and restart training from the last complete epoch instead of having to start training at the\n",
        "# beginning\n",
        "if FILE_SAVE == 1:\n",
        "    torch.save({\n",
        "        'epoch': TRAINING_NUM_EPOCHS - 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, FILE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFczZI-E_cJV"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# TEST\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# initialize test set statistics\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total   = 0\n",
        "\n",
        "# initialize class statistics\n",
        "class_correct = list(0. for i in range(DATA_NUM_CLASSES))\n",
        "class_total   = list(0. for i in range(DATA_NUM_CLASSES))\n",
        "\n",
        "# no weight update / no gradient needed\n",
        "with torch.no_grad():\n",
        "\n",
        "    # cycle through the test set\n",
        "    for data in dataloader_test:\n",
        "\n",
        "        # extract a batch of data and move it to the appropriate device\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass and prediction\n",
        "        outputs      = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # update test set statistics\n",
        "        test_total   = test_total + labels.size(0)\n",
        "        test_correct = test_correct + (predicted == labels).sum().item()\n",
        "\n",
        "        # update class statistics\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(labels.size(0)):\n",
        "            label                 = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label]   += 1\n",
        "\n",
        "# test set statistics\n",
        "print('Accuracy of test set = {0:5.2f}'.format((100.0*test_correct/test_total)))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYs5ZOXMkQju"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# DISPLAY\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# extract a batch of data\n",
        "data_iterator  = iter(dataloader_test)\n",
        "inputs, labels = data_iterator.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcna5J8NkX7f"
      },
      "source": [
        "# images and ground truth labels\n",
        "images    = torchvision.utils.make_grid(inputs)/2 + 0.5\n",
        "np_images = images.numpy()\n",
        "plt.imshow(np.transpose(np_images, (1, 2, 0)))\n",
        "# print('Ground truth = ', ' '.join('%5s' % DATA_CLASS_NAMES[labels[j]] for j in range(DATA_BATCH_SIZE)))\n",
        "\n",
        "# move it to the appropriate device\n",
        "inputs, labels = inputs.to(device), labels.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-eUYLhxkZlL"
      },
      "source": [
        "# forward pass and prediction\n",
        "outputs      = model(inputs)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# predicted labels\n",
        "print('Predicted    = ', ' '.join('%5s' % predicted[j] for j in range(DATA_BATCH_SIZE)))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}