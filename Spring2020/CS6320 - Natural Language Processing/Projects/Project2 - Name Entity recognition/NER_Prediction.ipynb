{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkAlyVTVqlB3",
        "colab_type": "text"
      },
      "source": [
        "The project uses a Google Colaboratory .ipynb file, since the computing power required was'nt met with my device.\n",
        "The project successfully ran on a hosted runtime having 35GB RAM and TPU selected.\n",
        "(One hot encoding takes a lot of memory.)\n",
        "\n",
        "All the required dependecies of the project can be included by running the cells of the notebook.\n",
        "You can run the notebook by pressing Ctrl+F9 or by clicking 'Run All' from the 'Runtime' menu.\n",
        "This notebook can be accessed from here: https://colab.research.google.com/drive/1Oc4ZKucV_Y8BIlPEENjo6GWtevnK-rKz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFZz6jJpyAJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkgRaA2yegbX",
        "colab_type": "code",
        "outputId": "31a9917b-d3de-4e6b-fbaa-39779eb0fa91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpLg2E4teabT",
        "colab_type": "code",
        "outputId": "687bc1d5-e028-4aae-8034-db9b78fa077c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py0LC6l5g4rV",
        "colab_type": "text"
      },
      "source": [
        "# Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW-gmLc6yCq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pos_lemmas(tagger,sentence):\n",
        "    # ex = 'The horse will race tomorrow. Race for outer space. Secretariat is expected to race tomorrow.'\n",
        "    # ex1 = 'Race for outer space.The horse will race tomorrow.'\n",
        "    # print(\"sentence is\",sentence)\n",
        "    if(tagger == 'nltk'):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        result = [pos_tag(sentence),[lemmatizer.lemmatize(word) for word in sentence]]\n",
        "        return result\n",
        "    elif(tagger == 'spacy'):   \n",
        "        doc = nlp_spacy(\" \".join(sentence)) \n",
        "        return [[token.pos_ for token in doc],[token.lemma_ for token in doc]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FegygtlQyHiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lemmas_based_pos_ner(tagger,file, isTest = False, existingVocab={},store_test_tokens_list=[]):\n",
        "    count_lines = 0\n",
        "    sentences = [[]]\n",
        "    sentences_ner = [[]]\n",
        "    sentence_counter = -1\n",
        "\n",
        "    tokens_ner_dict = {}\n",
        "    tokens_pos_dict = {}\n",
        "\n",
        "    def increment_sentence_counter(counter):\n",
        "        sentences.append([])\n",
        "        sentences_ner.append([])\n",
        "        return counter + 1\n",
        "\n",
        "    with open(file) as f:\n",
        "        # while(count_lines < limit):\n",
        "        while True:\n",
        "            line = f.readline()\n",
        "            count_lines += 1\n",
        "\n",
        "            #end of file, len(line) is 0 OR line is null\n",
        "            if not line:    \n",
        "                break\n",
        "\n",
        "            if line.find(\"-DOCSTART-\") != -1:\n",
        "                # print(count, line, \"Starting new document\")\n",
        "                continue\n",
        "\n",
        "            #for new lines, len(line) == 1 due to '\\n' character\n",
        "            if line == \"\\n\":\n",
        "                #skip for the first time\n",
        "                if sentence_counter < 0:\n",
        "                    sentence_counter = increment_sentence_counter(sentence_counter)\n",
        "                    continue\n",
        "\n",
        "                # print(count, \"New Sentence next\")\n",
        "                #Not seperating pos and lemma functions as we need from the same source of 'nltk' or 'spacy' or 'stanford'\n",
        "                pos_tags, lemmas = get_pos_lemmas(tagger,sentences[sentence_counter])\n",
        "\n",
        "                #now we got the correct pos_tags and lemmas for the sentence, now we have to store them\n",
        "                for pos,lemma,ner in zip(pos_tags,lemmas,sentences_ner[sentence_counter]):\n",
        "                    pos_tag = pos if tagger == 'spacy' else pos[1]\n",
        "                    if isTest:\n",
        "                        #lemma not in tokens_pos_dict is also not in tokens_ner_dict\n",
        "                        if lemma not in existingVocab:\n",
        "                            tokens_pos_dict[lemma] = 'UNK'\n",
        "                            tokens_ner_dict[lemma] = {'UNK':1}  \n",
        "                        elif lemma not in tokens_pos_dict:\n",
        "                            tokens_pos_dict[lemma] = pos_tag\n",
        "                            tokens_ner_dict[lemma] = {ner : 1}\n",
        "                        else:\n",
        "                            if ner in tokens_ner_dict[lemma]:\n",
        "                                tokens_ner_dict[lemma][ner] += 1\n",
        "                            else:\n",
        "                                tokens_ner_dict[lemma].update({ner : 1})\n",
        "         \n",
        "                    else:\n",
        "                        if lemma not in tokens_pos_dict:\n",
        "                            tokens_pos_dict[lemma] = pos_tag\n",
        "                            tokens_ner_dict[lemma] = {ner : 1}\n",
        "                        else:\n",
        "                            if ner in tokens_ner_dict[lemma]:\n",
        "                                tokens_ner_dict[lemma][ner] += 1\n",
        "                            else:\n",
        "                                tokens_ner_dict[lemma].update({ner : 1})\n",
        "                                                      \n",
        "                # print(\"sentence no.\",sentence_counter)\n",
        "                sentence_counter = increment_sentence_counter(sentence_counter)        \n",
        "                continue\n",
        "\n",
        "            token, ner = line.split()\n",
        "            token_lower = token.lower()\n",
        "            if isTest:\n",
        "                store_test_tokens_list.append(token_lower)\n",
        "            sentences[sentence_counter].append(token_lower)\n",
        "            sentences_ner[sentence_counter].append(ner)\n",
        "\n",
        "    # print(tokens_ner_dict)\n",
        "    #get the most used ner tag for that lemma\n",
        "    for lemma in tokens_ner_dict:\n",
        "        tokens_ner_dict[lemma] = max(zip(tokens_ner_dict[lemma].values(),tokens_ner_dict[lemma].keys()))[1]\n",
        "\n",
        "    unique_pos_tags = list(np.unique(list(tokens_pos_dict.values())))\n",
        "    print(f\"There are {sentence_counter} sentences, {len(tokens_pos_dict)} unique tokens, and {len(unique_pos_tags)} POS Tags in the '{file}' corpus.\")\n",
        "    return tokens_pos_dict, tokens_ner_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLbJ0BaeyKAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_pos_lemma_ner(lemmas_mapped_pos,lemmas_based_ners):\n",
        "    unique_pos_tags = list(np.unique(list(lemmas_mapped_pos.values())))\n",
        "    lemmas = list(lemmas_mapped_pos.keys())\n",
        "    ners = list(lemmas_based_ners.values())\n",
        "    # print(unique_pos_tags,lemmas,ners)\n",
        "    return unique_pos_tags,lemmas,ners\n",
        "\n",
        "def make_integer_mappings(train,test):\n",
        "    mapped_integer = {}\n",
        "    uid = 0\n",
        "\n",
        "    for tr in train:\n",
        "        mapped_integer[tr] = uid\n",
        "        uid += 1\n",
        "    \n",
        "    unkwown_tag_uid = uid\n",
        "    mapped_integer['UNK'] = unkwown_tag_uid\n",
        "    uid += 1\n",
        "\n",
        "    for te in test:\n",
        "      if te not in mapped_integer:\n",
        "        mapped_integer[te] = uid\n",
        "        uid += 1\n",
        "\n",
        "    # print(mapped_integer)\n",
        "    return mapped_integer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qk5IBesyMsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_encoded_lemma_pos(lemma_pos,lemma_int_mapping,pos_int_mapping,one_hot_lemmas,one_hot_pos_tags):\n",
        "    \n",
        "    merged_lemma_pos = {}\n",
        "    for lemma in lemma_pos:\n",
        "        lemma_idx = lemma_int_mapping[lemma]\n",
        "        pos_idx = pos_int_mapping[lemma_pos[lemma]]\n",
        "\n",
        "        merged_lemma_pos[lemma] = np.hstack((one_hot_lemmas[lemma_idx],one_hot_pos_tags[pos_idx]))\n",
        "\n",
        "    # print(merged_lemma_pos)\n",
        "    return merged_lemma_pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupOMuDqcEum",
        "colab_type": "text"
      },
      "source": [
        "# Task 1 : Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxWpH5BvyV5I",
        "colab_type": "code",
        "outputId": "496f0648-e6a3-4dc4-be4e-b903bdfe0d41",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Task 1 : Data preprocessing#\n",
        "train_file = 'modified_train.txt'\n",
        "test_file = 'modified_test.txt'\n",
        "\n",
        "#available : 'nltk' and 'spacy'\n",
        "tagger = 'spacy'\n",
        "\n",
        "if tagger == 'spacy':\n",
        "    nlp_spacy = spacy.load(\"en_core_web_sm\") \n",
        "\n",
        "test_tokens_list = []\n",
        "\n",
        "train_lemma_mapped_pos, train_lemma_mapped_ner = get_lemmas_based_pos_ner(tagger,train_file)\n",
        "test_lemma_mapped_pos, test_lemma_mapped_ner = get_lemmas_based_pos_ner(tagger,test_file,True, train_lemma_mapped_pos,test_tokens_list)\n",
        "# print(train_lemma_mapped_pos,train_lemma_mapped_ner)\n",
        "# print(test_lemma_mapped_pos,test_lemma_mapped_ner)\n",
        "\n",
        "train_upos_tags, train_lemmas, train_ners = extract_pos_lemma_ner(train_lemma_mapped_pos,train_lemma_mapped_ner)\n",
        "test_upos_tags, test_lemmas, test_ners = extract_pos_lemma_ner(test_lemma_mapped_pos,test_lemma_mapped_ner)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 18451 sentences, 18623 unique tokens, and 17 POS Tags in the 'modified_train.txt' corpus.\n",
            "There are 3682 sentences, 7046 unique tokens, and 18 POS Tags in the 'modified_test.txt' corpus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRMsaDz51KVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the lemma and pos mapping based on the training and testing data\n",
        "lemma_mapped_integer = make_integer_mappings(train_lemmas,test_lemmas)\n",
        "pos_mapped_integer = make_integer_mappings(train_upos_tags,test_upos_tags)\n",
        "# unknown_tag_counter = lemma_unknown + pos_unknown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUWANabicLwb",
        "colab_type": "text"
      },
      "source": [
        "# Task 2 : Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VofysAbSyYVu",
        "colab_type": "code",
        "outputId": "8a0030f4-7a73-48d5-c1b1-b917bf77cc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Task 2 : Feature Engineering#\n",
        "\n",
        "lemma_dimension = len(lemma_mapped_integer)\n",
        "pos_dimension = len(pos_mapped_integer)\n",
        "print(lemma_dimension,pos_dimension)\n",
        "# print(lemma_mapped_integer.keys())\n",
        "\n",
        "one_hot_lemmas = np.eye(lemma_dimension)\n",
        "one_hot_pos_tags = np.eye(pos_dimension)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21002 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gPv6knl0HFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_one_hot_lemma_pos_encoded = merge_encoded_lemma_pos(train_lemma_mapped_pos,lemma_mapped_integer,pos_mapped_integer,one_hot_lemmas,one_hot_pos_tags)\n",
        "test_one_hot_lemma_pos_encoded = merge_encoded_lemma_pos(test_lemma_mapped_pos,lemma_mapped_integer,pos_mapped_integer,one_hot_lemmas,one_hot_pos_tags)\n",
        "# print(one_hot_lemma_pos_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7qjSG-EcPp-",
        "colab_type": "text"
      },
      "source": [
        "# Task 3 : Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0q6M5nexNr6",
        "colab_type": "code",
        "outputId": "51c206de-c2b2-408f-f09d-3a382f24fdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Task 3: Learning#\n",
        "train_input = list(train_one_hot_lemma_pos_encoded.values())\n",
        "train_output = list(train_lemma_mapped_ner.values())\n",
        "print(len(train_input),len(train_output))\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# model = LogisticRegression()\n",
        "\n",
        "train_start=time.time()\n",
        "model.fit(train_input,train_output)\n",
        "train_end = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18623 18623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjoSlcQ2cmXp",
        "colab_type": "text"
      },
      "source": [
        "# Task 4 : Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lmLV0egxRWY",
        "colab_type": "code",
        "outputId": "669ac42f-87d9-4745-8c31-db7a768e66f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Task 4 : Model Performance\n",
        "test_input = list(test_one_hot_lemma_pos_encoded.values())\n",
        "test_output = list(test_lemma_mapped_ner.values())\n",
        "print(len(test_input),len(test_output))\n",
        "test_start = time.time()\n",
        "predicted = model.predict(test_input)\n",
        "test_end = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7046 7046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKPKT_GIAx2h",
        "colab_type": "code",
        "outputId": "e68542fc-85ef-47a7-d0f8-021b04f48d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "training_time = train_end - train_start\n",
        "testing_time = test_end - test_start\n",
        "print(f'Training time = {training_time:0.2f} seconds')\n",
        "print(f'Testing time = {testing_time:0.2f} seconds')\n",
        "print(f'Model Accuracy: {accuracy_score(predicted,test_output)*100:0.3f}%')\n",
        "print(f'Model Throughput : {os.stat(test_file).st_size/(testing_time*1000)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time = 5.73 seconds\n",
            "Testing time = 6.28 seconds\n",
            "Model Accuracy: 57.352%\n",
            "Model Throughput : 60.45743907981308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_ZW35a4goMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use the predicted NER tags from the model for all the words of the test\n",
        "lemma_id = {}\n",
        "idx = 0\n",
        "for lemma in test_one_hot_lemma_pos_encoded:\n",
        "    lemma_id[lemma] = idx\n",
        "    idx += 1\n",
        "\n",
        "iter = 0\n",
        "test_token_list_output = []\n",
        "for token in test_tokens_list:\n",
        "    if tagger == 'nltk':\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        lemma = lemmatizer.lemmatize(token)\n",
        "    else:\n",
        "        lemma = nlp_spacy(token)[0].lemma_\n",
        "    if  lemma in test_lemma_mapped_ner:\n",
        "        idx = lemma_id[lemma]\n",
        "        test_token_list_output.append(predicted[idx])\n",
        "    else:\n",
        "        test_token_list_output.append('UNK')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YzRdrlfhBQY",
        "colab_type": "text"
      },
      "source": [
        "## Remove BIO-tag Violations for the predicted NER tags, if any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRysA0uWMY0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove the BIO Tag Violations\n",
        "idx = 0\n",
        "while idx < len(test_token_list_output):\n",
        "    spill = test_token_list_output[idx].split('-')\n",
        "    curr_idx = idx\n",
        "    while idx >= 0 and len(spill) > 1 and spill[0] == 'I':\n",
        "        spill_up = test_token_list_output[idx-1].split('-')\n",
        "        # print(idx,test_tokens_list[idx],test_token_list_output[idx],spill,spill_up)\n",
        "\n",
        "        if spill_up[0] == 'O':\n",
        "            test_token_list_output[idx] = \"B-\"+spill[1]\n",
        "            break\n",
        "        elif spill_up[0] == 'B' and spill_up[1] == spill[1]:\n",
        "            break\n",
        "        elif spill_up[0] == 'B':\n",
        "            test_token_list_output[idx] = \"I-\"+spill_up[1]\n",
        "            break\n",
        "        elif len(spill_up) > 1 and spill_up[1] != spill[1]:\n",
        "            test_token_list_output[idx] = \"I-\"+spill_up[1]\n",
        "        \n",
        "        spill = spill_up\n",
        "        idx -= 1\n",
        "\n",
        "    idx = curr_idx + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpDBJyONOYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual = []\n",
        "output = []\n",
        "iter = 0\n",
        "for token in test_tokens_list:\n",
        "    if tagger == 'nltk':\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        lemma = lemmatizer.lemmatize(token)\n",
        "    else:\n",
        "        lemma = nlp_spacy(token)[0].lemma_\n",
        "    if  lemma in test_lemma_mapped_ner:\n",
        "        idx = lemma_id[lemma]\n",
        "        # print(iter,idx,token,test_token_list_output[iter],test_lemma_mapped_ner[lemma])\n",
        "        output.append(test_token_list_output[iter])\n",
        "        actual.append(test_lemma_mapped_ner[lemma])\n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8LLTFc7hMOw",
        "colab_type": "text"
      },
      "source": [
        "# Final Accuracy and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0_II1o7UDwn",
        "colab_type": "code",
        "outputId": "a7bce2dd-b3aa-44e1-9c17-7f3e6e12fa02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "print(f'NER Test Token Accuracy: {accuracy_score(output,actual)*100:0.3f}%')\n",
        "print(classification_report(output,actual))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(output,actual))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NER Test Token Accuracy: 87.096%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.79      0.64      0.71      1614\n",
            "      B-MISC       0.76      0.15      0.25      2924\n",
            "       B-ORG       0.71      0.73      0.72      1173\n",
            "       B-PER       0.76      0.64      0.69       980\n",
            "       I-LOC       0.28      0.27      0.28       159\n",
            "      I-MISC       0.21      0.03      0.06       785\n",
            "       I-ORG       0.24      0.62      0.34       206\n",
            "       I-PER       0.33      0.26      0.29       564\n",
            "           O       0.98      0.98      0.98     37517\n",
            "         UNK       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87     45922\n",
            "   macro avg       0.51      0.43      0.43     45922\n",
            "weighted avg       0.92      0.87      0.88     45922\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 1029     5   133    17    70     0   111     8   241     0]\n",
            " [    4   432    25     5     0    68    13     0    60  2317]\n",
            " [   53    10   853    19     3     0   113    16   106     0]\n",
            " [   17     7    19   623     2     0     7   191   114     0]\n",
            " [    0     6     0     0    43     0    32     1     7    70]\n",
            " [    2     0     7     9    11    27    26    29    19   655]\n",
            " [    0     0     4     0     3     0   128     3    15    53]\n",
            " [    2     0     0    20    10     0     4   148    11   369]\n",
            " [  192   110   167   126    10    36   106    57 36713     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwthzPjL30ot",
        "colab_type": "text"
      },
      "source": [
        "# Analysis Report\n",
        "\n",
        "There are two kinds of accuracy reported in this:\n",
        "1. Model accuracy : This is the accuracy for the model being used for the feature 1-hot encodings for unique tokens.\n",
        "2. NER Test Token Accuracy : This is the accuracy of all the test tokens, using the above models predicted NER tags, and then calculating the accuracy metric and F1 score with that metric. (Also removing the BIO-tag violations)\n",
        "\n",
        "The best accuracy to be recorded is with GaussianNB ML algorithm, being 87.096%(NER Test Token Accuracy, Model Accuracy\t: 57.352%), and it used the 'spacy' library for its POS tagging and lemmatization tasks.\n",
        "\n",
        "The model can use either 'nltk' OR the 'spacy' library by changing the 'tagger' variable.\n",
        "For eg: tagger = 'nltk'\n",
        "or tagger = 'spacy'\n",
        "\n",
        "*Throughput - Size of testing file / Time taken for making prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCLC3lyf3sMQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Using NLTK library for POS tags and lemmatization:\n",
        "\n",
        "```\n",
        "With GaussianNB :\n",
        "    Training time \t\t\t    :\t10.03 seconds\n",
        "    Testing time \t\t\t      :\t8.46 seconds\n",
        "    Model Accuracy \t\t\t    :\t59.558%\n",
        "    Model Throughput \t\t    :\t44.876647561548765 Kbps\n",
        "    NER Test Token Accuracy :\t86.427%\n",
        "```\n",
        "\n",
        "\t\n",
        "\t\t\t\t  precision    recall  f1-score   support\n",
        "\n",
        "\t\t   B-LOC       0.88      0.81      0.84      1721\n",
        "\t\t  B-MISC       0.78      0.14      0.23      3467\n",
        "\t\t   B-ORG       0.73      0.71      0.72      1244\n",
        "\t\t   B-PER       0.88      0.83      0.85      1068\n",
        "\t\t   I-LOC       0.24      0.12      0.16       389\n",
        "\t\t  I-MISC       0.25      0.04      0.06       945\n",
        "\t\t   I-ORG       0.23      0.48      0.31       279\n",
        "\t\t   I-PER       0.46      0.28      0.35       658\n",
        "\t\t\t   O       0.99      0.98      0.99     36660\n",
        "\t\t\t UNK       0.00      0.00      0.00         0\n",
        "\n",
        "\t\taccuracy                           0.86     46431\n",
        "\t   macro avg       0.55      0.44      0.45     46431\n",
        "\tweighted avg       0.93      0.86      0.88     46431\n",
        "\n",
        "\tConfusion Matrix:\n",
        "\t[[ 1389     6   155    22    66     0    40     4    39     0]\n",
        "\t [    6   471    32     1    10    70    13     2    88  2774]\n",
        "\t [   62    14   886    11     7     0   159    20    85     0]\n",
        "\t [   10     8    23   885     7     0     8   113    14     0]\n",
        "\t [    0     6     1     0    48     0    61     0    12   261]\n",
        "\t [    2     0     1     7    20    35    37    41    29   773]\n",
        "\t [    0     0     2     0    16     0   133     4     8   116]\n",
        "\t [    0     1     0    24    12     0     3   181     1   436]\n",
        "\t [  108    96   113    56    10    34   117    25 36101     0]\n",
        "\t [    0     0     0     0     0     0     0     0     0     0]]\n",
        " \n",
        " \n",
        "Other Machine Learning models performed lesser than the GaussianNB in order\n",
        "\n",
        "\t\n",
        "```\n",
        "With RandomForestClassifier:\n",
        "\tTraining time \t\t\t\t: \t1363.65 seconds\n",
        "\tTesting time \t\t\t\t: \t9.86 seconds\n",
        "\tModel Accuracy\t\t\t\t:\t55.531%\n",
        "\tModel Throughput \t\t\t: \t38.473305967179336 Kbps\n",
        "\tNER Test Token Accuracy\t\t: \t84.179%\n",
        "\n",
        "With LogisticRegression:\n",
        "\tTraining time \t\t\t\t:\t35.96 seconds\n",
        "\tTesting time \t\t\t\t: \t0.73 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t48.770%\n",
        "\tModel Throughput \t\t\t: \t516.8888562358712 Kbps\n",
        "\tNER Test Token Accuracy\t\t: \t78.924%\n",
        "\n",
        "With MultinomialNB:\n",
        "\tTraining time \t\t\t\t: \t2.30 seconds\n",
        "\tTesting time \t\t\t\t: \t0.75 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t46.744%\n",
        "\tModel Throughput \t\t\t: \t502.7249905190382 Kbps\n",
        "\tNER Test Token Accuracy\t\t: \t78.351%\n",
        "\n",
        "With BernoulliNB:\n",
        "\tTraining time \t\t\t\t: \t6.41 seconds\n",
        "\tTesting time \t\t\t\t:\t1.96 seconds\n",
        "\tModel Accuracy\t\t\t\t:\t46.744%\n",
        "\tModel Throughput \t\t\t:\t193.69095921814971 Kbps\n",
        "\tNER Test Token Accuracy\t\t:\t78.346%\n",
        "```\n",
        "\n",
        "SVM was taking very, very long to train, so I did'nt continue with that.\n",
        "```\n",
        "\t\t\t\t\t\t\tGaussianNB\t\tBernoulliNB\t\tMultinomialNB\t\tLogisticRegression\t\tRandomForestClassifier\n",
        "Training Time\t\t\t\t10.03 s\t\t\t6.41s\t\t\t2.3s\t\t\t\t35.96s\t\t\t\t\t1363.65s\n",
        "Testing Time\t\t\t\t 8.46s\t\t\t  1.96s\t\t\t0.75s\t\t\t\t0.73s\t\t\t\t\t9.86s\n",
        "NER Test Token Accuracy\t  86.427%\t\t\t78.34%\t   \t78.351%\t\t\t\t78.924%\t\t\t\t84.179%\n",
        "Model Throughput\t\t\t 44.87 Kbps\t\t193.69 Kbps\t   502.72 Kbps\t\t\t516.88 Kbps\t\t\t38.57 Kbps\n",
        "```\n",
        "\n",
        "Overall analysis:\n",
        "GaussianNB and RandomForestClassifier gave good results, though the training time for RandomForestClassifier was long.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkWijWZ34PJk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Using Spacy library for POS tags and lemmatization:\n",
        "\n",
        "```\n",
        "With GaussianNB :\n",
        "\tTraining time \t\t\t\t: \t6.68 seconds\n",
        "\tTesting time \t\t\t\t:\t8.36 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t57.352%\n",
        "\tModel Throughput \t\t\t: \t45.39114866835412 Kbps\n",
        "\tNER Test Token Accuracy\t\t:\t87.096%\n",
        "```\n",
        "\n",
        "\t\t   precision    recall  f1-score   support\n",
        "\n",
        "\t\t   B-LOC       0.79      0.64      0.71      1614\n",
        "\t\t  B-MISC       0.76      0.15      0.25      2924\n",
        "\t\t   B-ORG       0.71      0.73      0.72      1173\n",
        "\t\t   B-PER       0.76      0.64      0.69       980\n",
        "\t\t   I-LOC       0.28      0.27      0.28       159\n",
        "\t\t  I-MISC       0.21      0.03      0.06       785\n",
        "\t\t   I-ORG       0.24      0.62      0.34       206\n",
        "\t\t   I-PER       0.33      0.26      0.29       564\n",
        "\t\t\t   O       0.98      0.98      0.98     37517\n",
        "\t\t\t UNK       0.00      0.00      0.00         0\n",
        "\n",
        "\t\taccuracy                           0.87     45922\n",
        "\t   macro avg       0.51      0.43      0.43     45922\n",
        "\tweighted avg       0.92      0.87      0.88     45922\n",
        "\n",
        "\tConfusion Matrix:\n",
        "\t[[ 1029     5   133    17    70     0   111     8   241     0]\n",
        "\t [    4   432    25     5     0    68    13     0    60  2317]\n",
        "\t [   53    10   853    19     3     0   113    16   106     0]\n",
        "\t [   17     7    19   623     2     0     7   191   114     0]\n",
        "\t [    0     6     0     0    43     0    32     1     7    70]\n",
        "\t [    2     0     7     9    11    27    26    29    19   655]\n",
        "\t [    0     0     4     0     3     0   128     3    15    53]\n",
        "\t [    2     0     0    20    10     0     4   148    11   369]\n",
        "\t [  192   110   167   126    10    36   106    57 36713     0]\n",
        "\t [    0     0     0     0     0     0     0     0     0     0]]\n",
        "\n",
        "\n",
        "```\n",
        "With RandomForestClassifier:\n",
        "\tTraining time = 728.77 seconds\n",
        "\tTesting time = 6.92 seconds\n",
        "\tModel Accuracy: 55.720%\n",
        "\tModel Throughput : 54.85789999684634\n",
        "\tNER Test Token Accuracy: 85.922%\n",
        "\n",
        "With LogisticRegression:\n",
        "\tTraining time \t\t\t\t: \t23.21 seconds\n",
        "\tTesting time \t\t\t\t: \t0.62 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t53.477%\n",
        "\tModel Throughput \t\t\t: \t611.1674115376123\n",
        "\tNER Test Token Accuracy\t\t: \t84.010%\n",
        "\t\n",
        "With MultinomialNB:\n",
        "\tTraining time \t\t\t\t: \t2.42 seconds\n",
        "\tTesting time \t\t\t\t: \t0.81 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t47.034%\n",
        "\tModel Throughput \t\t\t: \t468.5071185268847 Kbps\n",
        "\tNER Test Token Accuracy\t\t:\t81.194%\n",
        "\n",
        "With BernoulliNB:\n",
        "\tTraining time \t\t\t\t: \t5.78 seconds\n",
        "\tTesting time \t\t\t\t: \t1.18 seconds\n",
        "\tModel Accuracy\t\t\t\t: \t47.034%\n",
        "\tModel Throughput \t\t\t: \t320.9877634215475\n",
        "\tNER Test Token Accuracy\t\t: \t81.194%\n",
        "```\n",
        "```\n",
        "\t\t\t\t\t\t\t\tGaussianNB\t\tBernoulliNB\t\tMultinomialNB\t\tLogisticRegression\t\tRandomForestClassifier\n",
        "Training Time\t\t\t\t\t6.68 s\t\t\t5.78s\t\t\t2.42s\t\t\t\t23.21s\t\t\t\t\t728.77s\n",
        "Testing Time\t\t\t\t\t 8.36s\t\t\t1.18s\t\t\t 0.81s\t\t\t\t0.62s\t\t\t\t\t 6.92s\n",
        "NER Test Token Accuracy\t\t 87.096%\t\t\t81.194%\t\t  78.35%\t\t\t\t84.01%\t\t\t\t  85.922%\n",
        "Model Throughput\t\t\t\t45.39 Kbps\t\t320.98 Kbps\t   468.51 Kbps\t\t  611.16 Kbps\t\t\t  54.85 Kbps\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sczhCBtk4Ug1",
        "colab_type": "text"
      },
      "source": [
        "### Closing Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ncToWWm3xMu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Overall Spacy seems to perform better than 'nltk' with the above ML algorithms for the NER prediction task on the given datasets.\n",
        "However, 'nltk' was much faster to process the 'POS' and to lemmatize a token in comparison to 'spacy'.\n",
        "\n",
        "GaussianNB algorithm for Naive bayes and RandomForestClassifier for the Ensemble method, both using 'spacy' library performs good on the NER classification task."
      ]
    }
  ]
}